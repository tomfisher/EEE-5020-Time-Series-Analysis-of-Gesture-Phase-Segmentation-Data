{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gesture Phase Detection using Unsupervised and Supervised Learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    " ## 1.1 Important Links:\n",
    "- [Gestuture Phase Segmentation Dataset from UCI Repository](https://archive.ics.uci.edu/ml/datasets/Gesture+Phase+Segmentation)\n",
    "- [sci-kit learn classes for Quick Reference](http://scikit-learn.org/stable/modules/classes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 1.2 About the Dataset\n",
    "   --- Gesture Phase Segmentation consists in a temporal segmentation of gestures, performed by gesture researchers in\n",
    "       order to preprocess videos for further analysis. The description of gesture phase segmentation problem may be   found in MADEO et al. (2013a) and MADEO et al. (2013b).\n",
    "\n",
    "   --- The dataset is composed by seven videos recorded using Microsoft Kinect sensor. Three different users were asked to read three comic strips and to tell the stories in front of the sensor. Using Microsoft Kinect, we have obtained:\n",
    "       (a) a image of each frame, identified by a timestamp; \n",
    "       (b) a text file containing positions (coordinates x, y, z) of six articulation points -- left hand, right hand, left wrist, right wrist, head and spine, with each line in the file corresponding to a frame and identified by a timestamp. \n",
    "The images enabled a manual segmentation of each file by a specialist, providing a ground truth for classification.\n",
    "\n",
    "   --- The dataset is organized in 14 files: 7 raw files and 7 processed files, one for each video which compose the dataset. The name of the file refers to each video: the letter corresponds to the user (A, B, C) and the number corresponds to the story (1, 2, 3). The raw files contain the information obtained from Microsoft Kinect, described above. The processed file contains vectorial and scalar velocity and acceleration of left hand, right hand, left wrist, and right wrist. These measures were obtained after normalizing positions of hand and wrists considering the position of head and spine, and using a displacement equal to 3 in order to measure velocity, as described in MADEO et al. (2013c).\n",
    "\n",
    "### Number of Instances: \n",
    "\n",
    "\tA1 - 1747 frames\n",
    "\tA2 - 1264 frames\n",
    "\tA3 - 1834 frames\n",
    "\tB1 - 1073 frames\n",
    "\tB3 - 1423 frames\n",
    "\tC1 - 1111 frames\n",
    "\tC3 - 1448 frames\n",
    "\n",
    "### Number of Attributes: \n",
    "\n",
    "\t\n",
    "   - Raw files (*_raw.csv): 18 numeric attributes (double), a timestamp (integer) and a class attribute (nominal).\n",
    "   - Processed files (*_va3.csv): 32 numeric attributes (double) and a class attribute (nominal).\n",
    "    \n",
    "\tA feature vector with up to 51 numeric attributes can be generated with the two files mentioned above.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "#### Raw files:\n",
    "\n",
    "   1. lhx - Position of left hand (x coordinate)\n",
    "   2. lhy - Position of left hand (y coordinate)\n",
    "   3. lhz - Position of left hand (z coordinate)\n",
    "   4. rhx - Position of right hand (x coordinate)\n",
    "   5. rhy - Position of right hand (y coordinate)\n",
    "   6. rhz - Position of right hand (z coordinate)\n",
    "   7. hx - Position of head (x coordinate)\n",
    "   8. hy - Position of head  (y coordinate)\n",
    "   9. hz - Position of head  (z coordinate)\n",
    "   10. sx - Position of spine (x coordinate)\n",
    "   11. sy - Position of spine (y coordinate)\n",
    "   12. sz - Position of spine (z coordinate)\n",
    "   13. lwx - Position of left wrist (x coordinate)\n",
    "   14. lwy - Position of left wrist (y coordinate)\n",
    "   15. lwz - Position of left wrist (z coordinate)\n",
    "   16. rwx - Position of right wrist (x coordinate)\n",
    "   17. rwy - Position of right wrist (y coordinate)\n",
    "   18. rwz - Position of right wrist (z coordinate)\n",
    "   19. timestamp - \n",
    "   20. phase: \n",
    "\t\t-- Rest\n",
    "\t\t-- Preparation\n",
    "\t\t-- Stroke\n",
    "\t\t-- Hold\n",
    "\t\t-- Retraction\n",
    "\n",
    "#### Processed files:\n",
    "\n",
    "   1. Vectorial velocity of left hand (x coordinate)\n",
    "   2. Vectorial velocity of left hand (y coordinate)\n",
    "   3. Vectorial velocity of left hand (z coordinate)\n",
    "   4. Vectorial velocity of right hand (x coordinate)\n",
    "   5. Vectorial velocity of right hand (y coordinate)\n",
    "   6. Vectorial velocity of right hand (z coordinate)\n",
    "   7. Vectorial velocity of left wrist (x coordinate)\n",
    "   8. Vectorial velocity of left wrist (y coordinate)\n",
    "   9. Vectorial velocity of left wrist (z coordinate)\n",
    "   10. Vectorial velocity of right wrist (x coordinate)\n",
    "   11. Vectorial velocity of right wrist (y coordinate)\n",
    "   12. Vectorial velocity of right wrist (z coordinate)\n",
    "   13. Vectorial acceleration of left hand (x coordinate)\n",
    "   14. Vectorial acceleration of left hand (y coordinate)\n",
    "   15. Vectorial acceleration of left hand (z coordinate)\n",
    "   16. Vectorial acceleration of right hand (x coordinate)\n",
    "   17. Vectorial acceleration of right hand (y coordinate)\n",
    "   18. Vectorial acceleration of right hand (z coordinate)\n",
    "   19. Vectorial acceleration of left wrist (x coordinate)\n",
    "   20. Vectorial acceleration of left wrist (y coordinate)\n",
    "   21. Vectorial acceleration of left wrist (z coordinate)\n",
    "   22. Vectorial acceleration of right wrist (x coordinate)\n",
    "   23. Vectorial acceleration of right wrist (y coordinate)\n",
    "   24. Vectorial acceleration of right wrist (z coordinate)\n",
    "   25. Scalar velocity of left hand\n",
    "   26. Scalar velocity of right hand\n",
    "   27. Scalar velocity of left wrist\n",
    "   28. Scalar velocity of right wrist\n",
    "   29. Scalar velocity of left hand\n",
    "   30. Scalar velocity of right hand\n",
    "   31. Scalar velocity of left wrist\n",
    "   32. Scalar velocity of right wrist\n",
    "   33. phase:\n",
    "\t\t-- D (rest position, from portuguese \"descanso\")\n",
    "\t\t-- P (preparation)\n",
    "\t\t-- S (stroke)\n",
    "\t\t-- H (hold)\n",
    "\t\t-- R (retraction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 2. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.1 Reading the '.csv' Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read .csv from provided dataset\n",
    "csv_filename01=\"./Dataset/a1_raw.csv\"\n",
    "csv_filename02=\"./Dataset/a1_va3.csv\"\n",
    "csv_filename03=\"./Dataset/a2_raw.csv\"\n",
    "csv_filename04=\"./Dataset/a2_va3.csv\"\n",
    "csv_filename05=\"./Dataset/a3_raw.csv\"\n",
    "csv_filename06=\"./Dataset/a3_va3.csv\"\n",
    "\n",
    "csv_filename07=\"./Dataset/b1_raw.csv\"\n",
    "csv_filename08=\"./Dataset/b1_va3.csv\"\n",
    "csv_filename09=\"./Dataset/b3_raw.csv\"\n",
    "csv_filename10=\"./Dataset/b3_va3.csv\"\n",
    "\n",
    "csv_filename11=\"./Dataset/c1_raw.csv\"\n",
    "csv_filename12=\"./Dataset/c1_va3.csv\"\n",
    "csv_filename13=\"./Dataset/c3_raw.csv\"\n",
    "csv_filename14=\"./Dataset/c3_va3.csv\"\n",
    "\n",
    "# df=pd.read_csv(csv_filename,index_col=0)\n",
    "df1=pd.read_csv(\"./Dataset/a1_raw.csv\" , skiprows=[1,2,3,4])\n",
    "df2=pd.read_csv(./Dataset/a1_va3.csv\")\n",
    "df3=pd.read_csv(./Dataset/a2_raw.csv , skiprows=[1,2,3,4])\n",
    "df4=pd.read_csv(./Dataset/a2_va3.csv)\n",
    "df5=pd.read_csv(./Dataset/a3_raw.csv , skiprows=[1,2,3,4])\n",
    "df6=pd.read_csv(./Dataset/a3_va3.csv)\n",
    "df7=pd.read_csv(./Dataset/b1_raw.csv , skiprows=[1,2,3,4])\n",
    "df8=pd.read_csv(./Dataset/b1_va3.csv)\n",
    "df9=pd.read_csv(./Dataset/b3_raw.csv , skiprows=[1,2,3,4])\n",
    "df10=pd.read_csv(csv_filename10)\n",
    "df11=pd.read_csv(csv_filename11 , skiprows=[1,2,3,4])\n",
    "df12=pd.read_csv(csv_filename12)\n",
    "df13=pd.read_csv(csv_filename13 , skiprows=[1,2,3,4])\n",
    "df14=pd.read_csv(csv_filename14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.2 Removing the 'timestamp' & 'phase' labels from unprocessed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df1.drop('timestamp',axis=1,inplace=True)\n",
    "df1.drop('phase',axis=1,inplace=True)\n",
    "df3.drop('timestamp',axis=1,inplace=True)\n",
    "df3.drop('phase',axis=1,inplace=True)\n",
    "df5.drop('timestamp',axis=1,inplace=True)\n",
    "df5.drop('phase',axis=1,inplace=True)\n",
    "df7.drop('timestamp',axis=1,inplace=True)\n",
    "df7.drop('phase',axis=1,inplace=True)\n",
    "df9.drop('timestamp',axis=1,inplace=True)\n",
    "df9.drop('phase',axis=1,inplace=True)\n",
    "df11.drop('timestamp',axis=1,inplace=True)\n",
    "df11.drop('phase',axis=1,inplace=True)\n",
    "df13.drop('timestamp',axis=1,inplace=True)\n",
    "df13.drop('phase',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.3 Visualising the Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.4 Visualising the Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#df2.Phase.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Visualising the Column Labels in the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#df2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.5 Renaming 'Phase' Column for convinience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df2.rename(columns={'Phase': 'phase'}, inplace=True)\n",
    "df4.rename(columns={'Phase': 'phase'}, inplace=True)\n",
    "df6.rename(columns={'Phase': 'phase'}, inplace=True)\n",
    "df8.rename(columns={'Phase': 'phase'}, inplace=True)\n",
    "df10.rename(columns={'Phase': 'phase'}, inplace=True)\n",
    "df12.rename(columns={'Phase': 'phase'}, inplace=True)\n",
    "df14.rename(columns={'Phase': 'phase'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.6 Concatenating the Dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p1 = pd.concat([df1,df2],axis=1)\n",
    "p2 = pd.concat([df3,df4],axis=1)\n",
    "p3 = pd.concat([df5,df6],axis=1)\n",
    "p4 = pd.concat([df7,df8],axis=1)\n",
    "p5 = pd.concat([df9,df10],axis=1)\n",
    "p6 = pd.concat([df11,df12],axis=1)\n",
    "p7 = pd.concat([df13,df14],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df= pd.concat([p1,p2,p3,p4,p5,p6,p7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.7 Encoding Phase Labels and Estimating number of instances of Differrent Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D', 'P', 'S', 'H', 'R'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.phase.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['phase'] = le.fit_transform(df['phase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lhx</th>\n",
       "      <th>lhy</th>\n",
       "      <th>lhz</th>\n",
       "      <th>rhx</th>\n",
       "      <th>rhy</th>\n",
       "      <th>rhz</th>\n",
       "      <th>hx</th>\n",
       "      <th>hy</th>\n",
       "      <th>hz</th>\n",
       "      <th>sx</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phase</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>...</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "      <td>2741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>...</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>...</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "      <td>2097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>...</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "      <td>1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>...</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "      <td>2950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lhx   lhy   lhz   rhx   rhy   rhz    hx    hy    hz    sx  ...     23  \\\n",
       "phase                                                              ...          \n",
       "0      2741  2741  2741  2741  2741  2741  2741  2741  2741  2741  ...   2741   \n",
       "1       998   998   998   998   998   998   998   998   998   998  ...    998   \n",
       "2      2097  2097  2097  2097  2097  2097  2097  2097  2097  2097  ...   2097   \n",
       "3      1087  1087  1087  1087  1087  1087  1087  1087  1087  1087  ...   1087   \n",
       "4      2950  2950  2950  2950  2950  2950  2950  2950  2950  2950  ...   2950   \n",
       "\n",
       "         24    25    26    27    28    29    30    31    32  \n",
       "phase                                                        \n",
       "0      2741  2741  2741  2741  2741  2741  2741  2741  2741  \n",
       "1       998   998   998   998   998   998   998   998   998  \n",
       "2      2097  2097  2097  2097  2097  2097  2097  2097  2097  \n",
       "3      1087  1087  1087  1087  1087  1087  1087  1087  1087  \n",
       "4      2950  2950  2950  2950  2950  2950  2950  2950  2950  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('phase').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 4, 1, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.phase.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.8 Randomising the Data before Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lhx</th>\n",
       "      <th>lhy</th>\n",
       "      <th>lhz</th>\n",
       "      <th>rhx</th>\n",
       "      <th>rhy</th>\n",
       "      <th>rhz</th>\n",
       "      <th>hx</th>\n",
       "      <th>hy</th>\n",
       "      <th>hz</th>\n",
       "      <th>sx</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.003160</td>\n",
       "      <td>4.278530</td>\n",
       "      <td>1.542866</td>\n",
       "      <td>4.985812</td>\n",
       "      <td>4.182155</td>\n",
       "      <td>1.520330</td>\n",
       "      <td>5.037557</td>\n",
       "      <td>1.619226</td>\n",
       "      <td>1.778925</td>\n",
       "      <td>5.052367</td>\n",
       "      <td>...</td>\n",
       "      <td>1.880800e-04</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.064488</td>\n",
       "      <td>4.290401</td>\n",
       "      <td>1.542146</td>\n",
       "      <td>4.955739</td>\n",
       "      <td>4.163175</td>\n",
       "      <td>1.511876</td>\n",
       "      <td>5.037724</td>\n",
       "      <td>1.618397</td>\n",
       "      <td>1.779722</td>\n",
       "      <td>5.045395</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.500000e-07</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.067825</td>\n",
       "      <td>4.290883</td>\n",
       "      <td>1.542058</td>\n",
       "      <td>4.928284</td>\n",
       "      <td>4.157637</td>\n",
       "      <td>1.511306</td>\n",
       "      <td>5.038332</td>\n",
       "      <td>1.618043</td>\n",
       "      <td>1.780080</td>\n",
       "      <td>5.045374</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.920000e-05</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.070332</td>\n",
       "      <td>4.290677</td>\n",
       "      <td>1.541985</td>\n",
       "      <td>4.916637</td>\n",
       "      <td>4.151067</td>\n",
       "      <td>1.510510</td>\n",
       "      <td>5.038742</td>\n",
       "      <td>1.618044</td>\n",
       "      <td>1.780114</td>\n",
       "      <td>5.045767</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.184000e-05</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.071611</td>\n",
       "      <td>4.290927</td>\n",
       "      <td>1.542046</td>\n",
       "      <td>4.906132</td>\n",
       "      <td>4.143034</td>\n",
       "      <td>1.509449</td>\n",
       "      <td>5.042224</td>\n",
       "      <td>1.618561</td>\n",
       "      <td>1.780209</td>\n",
       "      <td>5.047422</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.015000e-05</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        lhx       lhy       lhz       rhx       rhy       rhz        hx  \\\n",
       "0  5.003160  4.278530  1.542866  4.985812  4.182155  1.520330  5.037557   \n",
       "1  5.064488  4.290401  1.542146  4.955739  4.163175  1.511876  5.037724   \n",
       "2  5.067825  4.290883  1.542058  4.928284  4.157637  1.511306  5.038332   \n",
       "3  5.070332  4.290677  1.541985  4.916637  4.151067  1.510510  5.038742   \n",
       "4  5.071611  4.290927  1.542046  4.906132  4.143034  1.509449  5.042224   \n",
       "\n",
       "         hy        hz        sx  ...              24        25        26  \\\n",
       "0  1.619226  1.778925  5.052367  ...    1.880800e-04  0.005133  0.010400   \n",
       "1  1.618397  1.779722  5.045395  ...   -7.500000e-07  0.005093  0.005756   \n",
       "2  1.618043  1.780080  5.045374  ...   -3.920000e-05  0.002406  0.003279   \n",
       "3  1.618044  1.780114  5.045767  ...   -3.184000e-05  0.001416  0.001334   \n",
       "4  1.618561  1.780209  5.047422  ...   -2.015000e-05  0.000158  0.001709   \n",
       "\n",
       "         27        28        29        30        31        32  phase  \n",
       "0  0.000646  0.007871  0.004631  0.000963  0.000092  0.000438      0  \n",
       "1  0.000573  0.003459  0.000730  0.000332  0.000012  0.000433      0  \n",
       "2  0.000452  0.003261  0.002412  0.000852  0.000042  0.000202      0  \n",
       "3  0.000493  0.001358  0.000313  0.000611  0.000029  0.000596      0  \n",
       "4  0.000325  0.001713  0.000203  0.000069  0.000038  0.000069      0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### After:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lhx</th>\n",
       "      <th>lhy</th>\n",
       "      <th>lhz</th>\n",
       "      <th>rhx</th>\n",
       "      <th>rhy</th>\n",
       "      <th>rhz</th>\n",
       "      <th>hx</th>\n",
       "      <th>hy</th>\n",
       "      <th>hz</th>\n",
       "      <th>sx</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>phase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>6.171766</td>\n",
       "      <td>3.673885</td>\n",
       "      <td>1.540934</td>\n",
       "      <td>5.183923</td>\n",
       "      <td>2.342675</td>\n",
       "      <td>1.462960</td>\n",
       "      <td>4.993442</td>\n",
       "      <td>1.630638</td>\n",
       "      <td>1.758757</td>\n",
       "      <td>4.989823</td>\n",
       "      <td>...</td>\n",
       "      <td>4.888200e-04</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.019398</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.019363</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>1.598923</td>\n",
       "      <td>4.018676</td>\n",
       "      <td>2.127240</td>\n",
       "      <td>3.447668</td>\n",
       "      <td>3.961191</td>\n",
       "      <td>2.194116</td>\n",
       "      <td>2.406612</td>\n",
       "      <td>0.866565</td>\n",
       "      <td>2.419828</td>\n",
       "      <td>2.433447</td>\n",
       "      <td>...</td>\n",
       "      <td>2.370000e-05</td>\n",
       "      <td>0.002486</td>\n",
       "      <td>0.001640</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.900734</td>\n",
       "      <td>5.139158</td>\n",
       "      <td>1.966193</td>\n",
       "      <td>3.518129</td>\n",
       "      <td>3.974145</td>\n",
       "      <td>2.017433</td>\n",
       "      <td>2.873748</td>\n",
       "      <td>1.309875</td>\n",
       "      <td>2.223579</td>\n",
       "      <td>2.622210</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.200000e-07</td>\n",
       "      <td>0.016789</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>1.877504</td>\n",
       "      <td>4.600049</td>\n",
       "      <td>2.244735</td>\n",
       "      <td>2.388666</td>\n",
       "      <td>4.047450</td>\n",
       "      <td>2.220921</td>\n",
       "      <td>2.251689</td>\n",
       "      <td>0.814129</td>\n",
       "      <td>2.417510</td>\n",
       "      <td>2.389094</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.060000e-05</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.003729</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>5.368234</td>\n",
       "      <td>3.686430</td>\n",
       "      <td>1.511358</td>\n",
       "      <td>5.200821</td>\n",
       "      <td>3.733999</td>\n",
       "      <td>1.513813</td>\n",
       "      <td>5.448239</td>\n",
       "      <td>1.473407</td>\n",
       "      <td>1.781345</td>\n",
       "      <td>5.476373</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.054000e-05</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lhx       lhy       lhz       rhx       rhy       rhz        hx  \\\n",
       "1087  6.171766  3.673885  1.540934  5.183923  2.342675  1.462960  4.993442   \n",
       "663   1.598923  4.018676  2.127240  3.447668  3.961191  2.194116  2.406612   \n",
       "167   1.900734  5.139158  1.966193  3.518129  3.974145  2.017433  2.873748   \n",
       "603   1.877504  4.600049  2.244735  2.388666  4.047450  2.220921  2.251689   \n",
       "379   5.368234  3.686430  1.511358  5.200821  3.733999  1.513813  5.448239   \n",
       "\n",
       "            hy        hz        sx  ...              24        25        26  \\\n",
       "1087  1.630638  1.758757  4.989823  ...    4.888200e-04  0.001908  0.019398   \n",
       "663   0.866565  2.419828  2.433447  ...    2.370000e-05  0.002486  0.001640   \n",
       "167   1.309875  2.223579  2.622210  ...   -1.200000e-07  0.016789  0.001238   \n",
       "603   0.814129  2.417510  2.389094  ...   -1.060000e-05  0.004462  0.002820   \n",
       "379   1.473407  1.781345  5.476373  ...   -3.054000e-05  0.004301  0.004158   \n",
       "\n",
       "            27        28        29        30        31        32  phase  \n",
       "1087  0.001020  0.019363  0.000933  0.009907  0.000592  0.009903      4  \n",
       "663   0.002337  0.000369  0.000438  0.000202  0.000414  0.000048      2  \n",
       "167   0.014379  0.000946  0.000620  0.000031  0.000143  0.000017      3  \n",
       "603   0.003729  0.002076  0.000187  0.000232  0.000026  0.000122      0  \n",
       "379   0.000762  0.002550  0.005362  0.003775  0.000887  0.000067      0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.9 Extracting the Feautre & Label Vector + Splitting into Test & Train (60:40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cols = list(df.columns)\n",
    "features = cols\n",
    "features.remove('phase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9873, 50)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[features]\n",
    "y = df['phase']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split dataset to 60% training and 40% testing\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2.10 Normalize the Dataset for Easier Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 3. Clustering- an Unsupervised Learning Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Link: \n",
    "1. Sci-Kit Library on Clustering Methods: (http://scikit-learn.org/stable/modules/clustering.html#clustering)\n",
    "2. Sck-Kit Learn Metrics ()\n",
    "3. Comparing different clustering algorithms on Toy Datasets. (http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overview:\n",
    "Eventhough, we are provided with a labelled dataset for our analysis. We would for first part of our implementation, treat it as a unlabelled dataset and try to run clustering algorithms to find out the distinct group of data points namely:\n",
    "1. PCA\n",
    "2. Agglomerative Clustering\n",
    "3. KMeans\n",
    "4. Affinity Propogation\n",
    "5. MeanShift\n",
    "6. Mixture of Gaussian Models\n",
    "\n",
    "A similar comparartive study of various unsupervised classification algorithms on the Toy Dataset is provided in the link below.\n",
    "\n",
    "http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html#sphx-glr-auto-examples-cluster-plot-cluster-comparison-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1 PCA - Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It is a precursor step to any analysis that we may subject to our dataset. The above datset has a highly dimensional feature space consisting of 50 fetures. In such a high-dimensional space, Euclidean distances tend to become inflated and meaningless. This can severely impact our algorithms performance. Such a situation demands more data to train our model and this problem is called the 'Curse of Dimensionality.'\n",
    "\n",
    "The PCA algorithm solves this problem by finding out the features that explain the maximum variance. So, instead of training our models over 50 features we will be training them over 5 features that explain the maximum variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Apply PCA with the same number of dimensions as variables in the dataset\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "#pca = PCA(n_components=18)\n",
    "pca.fit(X)\n",
    "\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "\n",
    "#print(pca.components_)\n",
    "#print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(list(pca.explained_variance_ratio_),'-o')\n",
    "plt.title('Explained variance ratio as function of PCA components')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Component')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1.1 Create 'reduced_data' - a Feature Dataframe containing PCA components explaining Maximum Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First we reduce the data to two dimensions using PCA to capture variation\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(X)\n",
    "#print(reduced_data[:10])  # print upto 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "reduced_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.1.2 Applying KMeans on 'reduced_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=5)\n",
    "clusters = kmeans.fit(reduced_data)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot the decision boundary by building a mesh grid to populate a graph.\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "\n",
    "hx = (x_max-x_min)/1000.\n",
    "hy = (y_max-y_min)/1000.\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, hx), np.arange(y_min, y_max, hy))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = clusters.predict(np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Find the centroids for KMeans or the cluster means for GMM \n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "#print('*** K MEANS CENTROIDS ***')\n",
    "#print(centroids)\n",
    "\n",
    "# TRANSFORM DATA BACK TO ORIGINAL SPACE FOR ANSWERING 7\n",
    "\n",
    "#print('*** CENTROIDS TRANSFERED TO ORIGINAL SPACE ***')\n",
    "#print(pca.inverse_transform(centroids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='Nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.Paired,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='w', zorder=10)\n",
    "plt.title('Clustering on the seeds dataset (PCA-reduced data)\\n'\n",
    "          'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.2 Applying Agglomerative Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Reference Link: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html\n",
    "\n",
    "Other Links:\n",
    "- [What is a Connectivity Matrix?](https://people.hofstra.edu/geotrans/eng/methods/connectivitymatrix.html)\n",
    "- [What is Precision & Recall? What is a Confusion Matrix?](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n",
    "- [How to compute F-Score?](https://en.wikipedia.org/wiki/F1_score)\n",
    "- [What is a ROC Curve? How is it useful?](http://www.dataschool.io/roc-curves-and-auc-explained/)\n",
    "- [What is Cohen's Kappa?](https://en.wikipedia.org/wiki/Cohen's_kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ac = cluster.AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='complete')\n",
    "labels = ac.fit_predict(X)\n",
    "print('Cluster labels: %s' % labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.shape(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.3 K Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Reference Link: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans\n",
    "\n",
    "Other Links:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf = cluster.KMeans(init='k-means++', n_clusters=5, random_state=5)\n",
    "clf.fit(X_train)\n",
    "print(clf.labels_.shape)\n",
    "print(clf.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Predict clusters on testing data\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print (\"Addjusted rand score:{:.2}\".format(metrics.adjusted_rand_score(y_test, y_pred)))\n",
    "print (\"Homogeneity score:{:.2} \".format(metrics.homogeneity_score(y_test, y_pred)) )\n",
    "print (\"Completeness score: {:.2} \".format(metrics.completeness_score(y_test, y_pred)))\n",
    "print (\"Confusion matrix\")\n",
    "print (metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.4 Affinity Propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Reference Link: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AffinityPropagation.html#sklearn.cluster.AffinityPropagation\n",
    "Other Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Affinity propagation\n",
    "aff = cluster.AffinityPropagation()\n",
    "aff.fit(X_train)\n",
    "print(aff.cluster_centers_indices_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred = aff.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print (\"Addjusted rand score:{:.2}\".format(metrics.adjusted_rand_score(y_test, y_pred)))\n",
    "print (\"Homogeneity score:{:.2} \".format(metrics.homogeneity_score(y_test, y_pred)))\n",
    "print (\"Completeness score: {:.2} \".format(metrics.completeness_score(y_test, y_pred)))\n",
    "print (\"Confusion matrix\")\n",
    "print (metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.5 MeanShift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Reference Link: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MeanShift.html\n",
    "\n",
    "Other Links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ms = cluster.MeanShift()\n",
    "ms.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred = ms.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"Addjusted rand score:{:.2}\".format(metrics.adjusted_rand_score(y_test, y_pred))\n",
    "print \"Homogeneity score:{:.2} \".format(metrics.homogeneity_score(y_test, y_pred)) \n",
    "print \"Completeness score: {:.2} \".format(metrics.completeness_score(y_test, y_pred))\n",
    "print \"Confusion matrix\"\n",
    "print metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.6 Mixture of Guassian Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Reference Link: http://scikit-learn.org/stable/modules/mixture.html\n",
    "\n",
    "Other Links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a heldout dataset to estimate covariance type\n",
    "X_train_heldout, X_test_heldout, y_train_heldout, y_test_heldout = train_test_split(\n",
    "        X_train, y_train,test_size=0.25, random_state=42)\n",
    "\n",
    "for covariance_type in ['spherical','tied','diag','full']:\n",
    "    gm = mixture.GaussianMixture(n_components=100, covariance_type=covariance_type, random_state=42, n_init=5)\n",
    "    gm.fit(X_train_heldout)\n",
    "    y_pred=gm.predict(X_test_heldout)\n",
    "    print \"Adjusted rand score for covariance={}:{:.2}\".format(covariance_type, \n",
    "                                                               metrics.adjusted_rand_score(y_test_heldout, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3.7 KMeans vs. Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X1 = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import cm \n",
    "n=6\n",
    "c = []\n",
    "color=iter(cm.rainbow(np.linspace(0,1,n)))\n",
    "for i in range(n):\n",
    "    c.append(next(color))\n",
    "\n",
    "#**************************************************************************************************************#\n",
    "\n",
    "n = 5\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(8,6))\n",
    "\n",
    "#**************************************************************************************************************#\n",
    "\n",
    "km = KMeans(n_clusters= n , random_state=0)\n",
    "y_km = km.fit_predict(X1)\n",
    "\n",
    "for i in range(n):\n",
    "    ax1.scatter(X1[y_km==i,0], X1[y_km==i,1], c=c[i], marker='o', s=40, label='cluster{}'.format(i))   \n",
    "ax1.set_title('K-means clustering')\n",
    "\n",
    "#**************************************************************************************************************#\n",
    "\n",
    "ac = AgglomerativeClustering(n_clusters=n, affinity='euclidean', linkage='complete')\n",
    "y_ac = ac.fit_predict(X1)\n",
    "\n",
    "for i in range(n):\n",
    "    ax2.scatter(X1[y_ac==i,0], X1[y_ac==i,1], c=c[i], marker='o', s=40, label='cluster{}'.format(i))\n",
    "ax2.set_title('Agglomerative clustering')\n",
    "\n",
    "#**************************************************************************************************************#\n",
    "\n",
    "# Put a legend below current axis\n",
    "plt.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "#plt.savefig('./figures/kmeans_and_ac.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 4. Classification- Supervised Learning Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.0 Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score , classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First we reduce the data to two dimensions using PCA to capture variation\n",
    "#pca = PCA(n_components=10)\n",
    "#X = pca.fit_transform(X)\n",
    "#print(reduced_data[:10])  # print upto 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# split dataset to 60% training and 40% testing\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((5923, 50), (5923,), (3950, 50), (3950,))\n"
     ]
    }
   ],
   "source": [
    "print (X_train.shape, y_train.shape,X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.0.2 Cross Validation Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Link: (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "\n",
    "Point to Note:\n",
    "- #### sklearn.model_selection.cross_val_score : (estimator,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.0.3 Feature Scaling\n",
    "Link: (https://www.analyticsvidhya.com/blog/2016/07/practical-guide-data-preprocessing-python-scikit-learn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#1. MinMax Scaling\n",
    "min_max=MinMaxScaler()\n",
    "X_train_minmax=min_max.fit_transform(X_train)\n",
    "X_test_minmax =min_max.fit_transform(X_test)\n",
    "\n",
    "#2. Scale\n",
    "X_train_scale =scale(X_train)\n",
    "X_test_scale  =scale(X_test)\n",
    "\n",
    "#3. Standard Scaler\n",
    "X_train_Stdscaler = StandardScaler().fit_transform(X_train)\n",
    "X_test_Stdscaler = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.1 Decision Tree accuracy and time elapsed caculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(min_samples_split=20,random_state=99)\n",
    "# dt = DecisionTreeClassifier(min_samples_split=20,max_depth=5,random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross result========\n",
      "[ 0.75316136  0.77884615  0.75025329  0.73796249  0.77546883]\n",
      "0.75913842502\n",
      "('time elapsed: ', 3.512260913848877)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt0=time()\n",
    "\n",
    "print (\"cross result========\")\n",
    "scores = model_selection.cross_val_score(dt, X,y, cv=5)\n",
    "print (scores)\n",
    "print (scores.mean())\n",
    "tt1=time()\n",
    "print (\"time elapsed: \", tt1-tt0)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.1.1 Implementation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree: Case-1: Normal Unprocessed Data\n",
      "('Acurracy: ', 0.71772151898734182)\n",
      "('time elapsed: ', 0.4864768981933594)\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "print (\"DecisionTree: Case-1: Normal Unprocessed Data\")\n",
    "\n",
    "clf_dt1= dt.fit(X_train,y_train)\n",
    "\n",
    "print (\"Acurracy: \", clf_dt1.score(X_test,y_test))\n",
    "t1=time()\n",
    "print (\"time elapsed: \", t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.1.2 Implementation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree: Case-2: MinMax Feature Scaling\n",
      "('Acurracy: ', 0.40962025316455697)\n",
      "('time elapsed: ', 0.518604040145874)\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "print (\"DecisionTree: Case-2: MinMax Feature Scaling\")\n",
    "\n",
    "clf_dt2= dt.fit(X_train_minmax,y_train)\n",
    "\n",
    "print (\"Acurracy: \", clf_dt2.score(X_test_minmax,y_test))\n",
    "t1=time()\n",
    "print (\"time elapsed: \", t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.1.3 Implementation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree: Case-3: Scale\n",
      "('Acurracy: ', 0.66835443037974684)\n",
      "('time elapsed: ', 0.5103750228881836)\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "print (\"DecisionTree: Case-3: Scale\")\n",
    "\n",
    "clf_dt3= dt.fit(X_train_scale,y_train)\n",
    "\n",
    "print (\"Acurracy: \", clf_dt3.score(X_test_scale,y_test))\n",
    "t1=time()\n",
    "print (\"time elapsed: \", t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.1.4 Implementation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree: Case-4: Standard Scaler\n",
      "('Acurracy: ', 0.66835443037974684)\n",
      "('time elapsed: ', 0.48151302337646484)\n"
     ]
    }
   ],
   "source": [
    "t0=time()\n",
    "print (\"DecisionTree: Case-4: Standard Scaler\")\n",
    "\n",
    "clf_dt4= dt.fit(X_train_Stdscaler,y_train)\n",
    "\n",
    "print (\"Acurracy: \", clf_dt4.score(X_test_Stdscaler,y_test))\n",
    "t1=time()\n",
    "print (\"time elapsed: \", t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.2 Random Forest accuracy and time elapsed caculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross result========\n",
      "[ 0.90035407  0.90080972  0.9047619   0.90978206  0.91535732]\n",
      "0.906213014968\n",
      "('time elapsed: ', 13.290452003479004)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tt2=time()\n",
    "print (\"cross result========\")\n",
    "scores = model_selection.cross_val_score(rf, X,y, cv=5)\n",
    "print (scores)\n",
    "print (scores.mean())\n",
    "tt3=time()\n",
    "print (\"time elapsed: \", tt3-tt2)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.2.1 Implementation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t2=time()\n",
    "print (\"RandomForest: Case-1 : Normal\")\n",
    "clf_rf1 = rf.fit(X_train,y_train)\n",
    "print (\"Acurracy: \", clf_rf1.score(X_test,y_test))\n",
    "t3=time()\n",
    "\n",
    "print (\"time elapsed: \", t3-t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.2.2 Implementation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t2=time()\n",
    "print (\"RandomForest: Case-2 : MinMax Feature Scaling\")\n",
    "clf_rf2 = rf.fit(X_train_minmax,y_train)\n",
    "print (\"Acurracy: \", clf_rf2.score(X_test_minmax,y_test))\n",
    "t3=time()\n",
    "print (\"time elapsed: \", t3-t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.2.3 Implementation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t2=time()\n",
    "print (\"RandomForest: Case-3 : Scale\")\n",
    "clf_rf3 = rf.fit(X_train_scale,y_train)\n",
    "print (\"Acurracy: \", clf_rf3.score(X_test_scale,y_test))\n",
    "t3=time()\n",
    "print (\"time elapsed: \", t3-t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.2.4 Implementation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t2=time()\n",
    "print (\"RandomForest: Case-2 : MinMax Feature Scaling\")\n",
    "clf_rf4 = rf.fit(X_train_Stdscaler,y_train)\n",
    "print (\"Acurracy: \", clf_rf4.score(X_test_Stdscaler,y_test))\n",
    "t3=time()\n",
    "print (\"time elapsed: \", t3-t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.3 Naive Bayes accuracy and time elapsed caculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tt4=time()\n",
    "print (\"cross result========\")\n",
    "scores = model_selection.cross_val_score(nb, X,y, cv=5)\n",
    "print (scores)\n",
    "print (scores.mean())\n",
    "tt5=time()\n",
    "print (\"time elapsed: \", tt5-tt4)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t4=time()\n",
    "print (\"NaiveBayes\")\n",
    "clf_nb=nb.fit(X_train,y_train)\n",
    "print (\"Acurracy: \", clf_nb.score(X_test,y_test))\n",
    "t5=time()\n",
    "print (\"time elapsed: \", t5-t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.4 KNN accuracy and time elapsed caculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t6=time()\n",
    "print (\"KNN\")\n",
    "# knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn = KNeighborsClassifier()\n",
    "clf_knn=knn.fit(X_train, y_train)\n",
    "print (\"Acurracy: \", clf_knn.score(X_test,y_test) )\n",
    "t7=time()\n",
    "print (\"time elapsed: \", t7-t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tt6=time()\n",
    "print (\"cross result========\")\n",
    "scores = model_selection.cross_val_score(clf_knn, X,y, cv=5)\n",
    "print (scores)\n",
    "print (scores.mean())\n",
    "tt7=time()\n",
    "print (\"time elapsed: \", tt7-tt6)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.5 SVM Accuracy and Time Elapsed Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.5.1 SVM with a Linear Kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "t7=time()\n",
    "print (\"SVM\")\n",
    "\n",
    "svc = SVC()\n",
    "clf_svc=svc.fit(X_train_minmax, y_train)\n",
    "print (\"Acurracy: \", clf_svc.score(X_test_minmax,y_test) )\n",
    "t8=time()\n",
    "print (\"time elapsed: \", t8-t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tt7=time()\n",
    "print (\"cross result========\")\n",
    "scores = model_selection.cross_val_score(clf_svc, X,y, cv=5)\n",
    "print (scores)\n",
    "print (scores.mean())\n",
    "tt8=time()\n",
    "print (\"time elapsed: \", tt8-tt7)\n",
    "print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.5.2 SVM with Multiple Kernels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   35.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.698\n",
      "Best parameters set:\n",
      "\tC: 100\n",
      "\tkernel: 'rbf'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.98      0.88      1126\n",
      "          1       0.61      0.48      0.54       410\n",
      "          2       0.58      0.55      0.56       847\n",
      "          3       0.78      0.31      0.45       420\n",
      "          4       0.74      0.83      0.78      1147\n",
      "\n",
      "avg / total       0.71      0.72      0.70      3950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import model_selection\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10, 100]}\n",
    "\n",
    "grid = model_selection.GridSearchCV(svc, parameters, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print ('Best score: %0.3f' % grid.best_score_)\n",
    "\n",
    "print ('Best parameters set:')\n",
    "best_parameters = grid.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print ('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "predictions = grid.predict(X_test)\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.848\n",
      "Best parameters set:\n",
      "\tclf__C: 30\n",
      "\tclf__gamma: 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.98      0.94      1126\n",
      "          1       0.81      0.86      0.83       410\n",
      "          2       0.85      0.79      0.82       847\n",
      "          3       0.88      0.75      0.81       420\n",
      "          4       0.93      0.92      0.93      1147\n",
      "\n",
      "avg / total       0.89      0.89      0.88      3950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', SVC(kernel='rbf', gamma=0.01, C=100))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'clf__gamma': (0.01, 0.03, 0.1, 0.3, 1),\n",
    "    'clf__C': (0.1, 0.3, 1, 3, 10, 30),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print ('Best score: %0.3f' % grid_search.best_score_)\n",
    "\n",
    "print ('Best parameters set:')\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print ('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "predictions = grid_search.predict(X_test)\n",
    "print (classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "clf_gb = ske.GradientBoostingClassifier(n_estimators=50)\n",
    "test_classifier(clf_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 4.6 Leveraging weak learners via adaptive boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=1)\n",
    "\n",
    "ada = AdaBoostClassifier(base_estimator=tree,\n",
    "                         n_estimators=500, \n",
    "                         learning_rate=0.1,\n",
    "                         random_state=0)\n",
    "\n",
    "tree = tree.fit(X_train, y_train)\n",
    "y_train_pred = tree.predict(X_train)\n",
    "y_test_pred = tree.predict(X_test)\n",
    "\n",
    "tree_train = accuracy_score(y_train, y_train_pred)\n",
    "tree_test = accuracy_score(y_test, y_test_pred)\n",
    "print('Decision tree train/test accuracies %.3f/%.3f'\n",
    "      % (tree_train, tree_test))\n",
    "\n",
    "ada = ada.fit(X_train, y_train)\n",
    "y_train_pred = ada.predict(X_train)\n",
    "y_test_pred = ada.predict(X_test)\n",
    "\n",
    "ada_train = accuracy_score(y_train, y_train_pred) \n",
    "ada_test = accuracy_score(y_test, y_test_pred) \n",
    "print('AdaBoost train/test accuracies %.3f/%.3f'\n",
    "      % (ada_train, ada_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 5. Important Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Complete List of all\n",
    "http://scikit-learn.org/stable/modules/classes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
